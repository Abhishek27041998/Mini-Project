{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the libraries that will be used further\n",
    "\n",
    "from sklearn.feature_extraction.image import extract_patches_2d\n",
    "from sklearn.feature_extraction import image\n",
    "import numpy as np\n",
    "import cv2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading the input image\n",
    "\n",
    "img = cv2.imread('2.jpg')\n",
    "\n",
    "row,col,no_channel = img.shape\n",
    "\n",
    "#Getting the blue,green and red channel(2d array) from img\n",
    "b,g,r = cv2.split(img)\n",
    "\n",
    "#Window size(As specified in the paper) to slide across image for variance calculation\n",
    "window_shape = (6, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abhishek/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/image.py:287: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  indexing_strides = arr[slices].strides\n"
     ]
    }
   ],
   "source": [
    "#sklearn library to extract all 2d patches of specified window shape from each channel\n",
    "\n",
    "blue_patches = extract_patches_2d(b, window_shape)\n",
    "green_patches = extract_patches_2d(g, window_shape)\n",
    "red_patches = extract_patches_2d(r, window_shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables\n",
    "Dg = []\n",
    "Db = []\n",
    "\n",
    "Bl_pixels = []\n",
    "Gr_pixels = []\n",
    "Re_pixels = []\n",
    "\n",
    "#Estimating the pixels whose patch variation is < 0.9\n",
    "\n",
    "for i in range(len(blue_patches)):\n",
    "    bl = blue_patches[i]\n",
    "    gr = green_patches[i]\n",
    "    re = red_patches[i]\n",
    "    \n",
    "    bls = list(bl.flat)\n",
    "    grls = list(gr.flat)\n",
    "    rels = list(re.flat)\n",
    "    \n",
    "    if np.var(bl) < 0.9 or np.var(gr) < 0.9 or np.var(re) < 0.9:\n",
    "        Db.extend([a - b for a, b in zip(bls, rels)])\n",
    "        Dg.extend([a - b for a, b in zip(grls, rels)])\n",
    "\n",
    "        Bl_pixels.extend(bls)\n",
    "        Gr_pixels.extend(grls)\n",
    "        Re_pixels.extend(rels)\n",
    "\n",
    "#Getting the max of Db and Dg\n",
    "\n",
    "maxB = Db[0]\n",
    "maxG = Dg[0]\n",
    "indB = 0\n",
    "indG = 0\n",
    "\n",
    "ind = 0\n",
    "maxR = 0\n",
    "for i in range(1,len(Db)):\n",
    "    if maxB < Db[i] or maxG < Dg[i]:\n",
    "        if maxR < Re_pixels[i]:\n",
    "            ind = i\n",
    "            maxB = Db[i]\n",
    "            maxG = Dg[i]\n",
    "            maxR = Re_pixels[i]\n",
    "\n",
    "#Backlight Pixels\n",
    "Backlight = []\n",
    "\n",
    "Backlight.append(Bl_pixels[ind])\n",
    "Backlight.append(Gr_pixels[ind])\n",
    "Backlight.append(Re_pixels[ind])\n",
    "\n",
    "normBacklight = np.divide(Backlight,255)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([150, 176, 86], array([0.58823529, 0.69019608, 0.3372549 ]))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Backlight, normBacklight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lamda_b :  0.6924651162790698  lamda_g :  0.536416490486258\n"
     ]
    }
   ],
   "source": [
    "#Finding attenuation ratios, formula's  is taken from the paper.\n",
    "\n",
    "Sb = (-0.00113*450 + 1.6251)\n",
    "Sg = (-0.00113*540 + 1.6251)\n",
    "Sr = (-0.00113*620 + 1.6251)\n",
    "\n",
    "#Attenuation ratios\n",
    "\n",
    "lamda_b = (Sb*Backlight[2])/(Sr*Backlight[0])\n",
    "\n",
    "lamda_g = (Sg*Backlight[2])/(Sr*Backlight[1])\n",
    "\n",
    "print('lamda_b : ',lamda_b, ' lamda_g : ',lamda_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transmission Estimation : \n",
    "#i) Finding Attenuation curves.(Clustering , building KD Tree)\n",
    "\n",
    "#Normalize the input image to double precision.\n",
    "norm_img = cv2.normalize(img.astype('double'), None, 0.0, 1.0, cv2.NORM_MINMAX)\n",
    "\n",
    "\n",
    "#finding haze lines\n",
    "dist_from_backlight = np.zeros([row,col,no_channel],dtype = np.double)\n",
    "\n",
    "for i in range(no_channel):\n",
    "    dist_from_backlight[:,:,i] = norm_img[:,:,i]-normBacklight[i]\n",
    "\n",
    "    \n",
    "#calculating radius\n",
    "radius = np.sqrt((dist_from_backlight[:,:,0])**2 + (dist_from_backlight[:,:,1])**2 +(dist_from_backlight[:,:,2])**2 )\n",
    "\n",
    "#clustering the pixels\n",
    "dist_unit_radius = np.reshape(dist_from_backlight,(row*col,no_channel))\n",
    "dist_norm = np.sqrt(np.sum(dist_unit_radius**2,axis=0))\n",
    "dist_unit_radius = np.divide(dist_unit_radius,dist_norm)\n",
    "n_points = 1000\n",
    "\n",
    "#read the points from file\n",
    "file = open(\"two.txt\",\"r\")\n",
    "d = np.loadtxt(file)\n",
    "points = d.reshape(1000,3)\n",
    "\n",
    "file.close()\n",
    "\n",
    "from sklearn.neighbors import KDTree\n",
    "kdt = KDTree(points, leaf_size=50, metric='euclidean')\n",
    "\n",
    "nearest_dist, nearest_ind = kdt.query(dist_unit_radius, k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((538900, 1), (538900, 1))"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nearest_dist.shape,nearest_ind.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ii) Estimating Initial Relative Transmission\n",
    "\n",
    "#K = accumarray(ind,radius(:),[n_points,1],@max);\n",
    "\n",
    "K = np.zeros((n_points,1),dtype = np.double)\n",
    "\n",
    "uniqNearest_Ind = np.unique(nearest_ind)\n",
    "\n",
    "temp = radius.flatten()\n",
    "\n",
    "for item in uniqNearest_Ind:\n",
    "    indexes = np.where(nearest_ind == item)[0]\n",
    "    K[item] = np.max(temp[indexes])\n",
    "\n",
    "K_new = K[nearest_ind]\n",
    "\n",
    "radius_new = np.reshape(K_new,(row,col))\n",
    "\n",
    "transmission_estimation = np.divide(radius,radius_new)\n",
    "\n",
    "#Limit the transmission to the range [trans_min, 1] for numerical stability\n",
    "trans_min = 0.1;\n",
    "transmission_estimation[np.where(transmission_estimation == 0.0)[0]] = 0.1\n",
    "transmission_estimation[np.where(transmission_estimation > 1)[0]] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(634, 850)"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# iii) Refining the transmission using WLS Optimization\n",
    "\n",
    "# find bin counts for reliability - small bins (#pixels<50) do not comply with \n",
    "# the model assumptions and should be disregarded\n",
    "\n",
    "bin_count = np.zeros((1000,1),dtype=int)\n",
    "\n",
    "uniqNearest_Ind = np.unique(nearest_ind)\n",
    "\n",
    "for item in uniqNearest_Ind:\n",
    "    bin_count[item] = np.sum(nearest_ind[:] == item)\n",
    "\n",
    "bin_count_map = bin_count[nearest_ind]\n",
    "\n",
    "bin_count_map = bin_count_map.reshape((row,col))\n",
    "\n",
    "bin_count_map.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bin_eval_fun(x):\n",
    "    res = np.zeros((x.shape[0],x.shape[1]))\n",
    "    \n",
    "    for i in range(x.shape[0]):\n",
    "        for j in range(x.shape[1]):\n",
    "            res[i,j] = min(1,x[i,j]/50)\n",
    "            \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate std - this is the data-term weight\n",
    "\n",
    "K_std = np.zeros((n_points,1))\n",
    "\n",
    "radius_flat = radius.flatten()\n",
    "\n",
    "uniqRadius = np.unique(radius_flat)\n",
    "\n",
    "for item in uniqNearest_Ind:\n",
    "    indexes = np.where(nearest_ind == item)[0]\n",
    "    \n",
    "    K_std[item] = np.std(radius_flat[indexes])\n",
    "\n",
    "radius_std = K_std[nearest_ind]\n",
    "\n",
    "radius_std = radius_std.reshape((row,col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "def radius_eval_fun(r):\n",
    "    res = np.zeros((r.shape[0],r.shape[1]))\n",
    "    \n",
    "    for i in range(r.shape[0]):\n",
    "        for j in range(r.shape[1]):\n",
    "            res[i,j] = min(1,3*max(0.001,r[i,j] - 0.1))\n",
    "\n",
    "    \n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "radius_reliability = radius_eval_fun(np.divide(radius_std,max(radius_std.flatten())))\n",
    "\n",
    "data_term_weight = bin_eval_fun(bin_count_map) * radius_reliability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WLS Optimization\n",
    "# Refered from Github : https://github.com/danaberman/non-local-dehazing (modified)\n",
    "\n",
    "r_trans = np.array(transmission_estimation)\n",
    "\n",
    "L = np.log(r_trans)\n",
    "\n",
    "lamda = 0.05\n",
    "smallNum = 0.00001\n",
    "\n",
    "r,c = r_trans.shape\n",
    "\n",
    "k = r*c\n",
    "\n",
    "dy = np.diff(L,0,0)\n",
    "\n",
    "old_dy = dy\n",
    "absDy = abs(dy)\n",
    "\n",
    "power = (np.power(absDy,2) + smallNum)       #Github Impl\n",
    "\n",
    "dy = np.divide(lamda,power)\n",
    "\n",
    "dy = np.pad(dy,(1,0),'constant')\n",
    "\n",
    "dy = dy.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "dx = np.diff(L,0,1)\n",
    "\n",
    "old_dx = dx\n",
    "\n",
    "absDx = abs(dx)\n",
    "\n",
    "powerDx = (np.power(absDx,2) + smallNum)\n",
    "\n",
    "dx = np.divide(lamda,powerDx)\n",
    "\n",
    "dx = np.pad(dx,(0,1),'constant')\n",
    "\n",
    "dx = dx.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "lapMat = np.zeros(shape=(len(dx),2))\n",
    "lapMat[:,0] = dx\n",
    "lapMat[:,1] = dy\n",
    "\n",
    "d = [-r,-1]\n",
    "\n",
    "lapMat = np.transpose(lapMat)\n",
    "\n",
    "import scipy\n",
    "\n",
    "reslapMat = scipy.sparse.spdiags(lapMat,d,k,k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(538900, 538900)"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reslapMat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = dx\n",
    "\n",
    "w = np.lib.pad(dx,(r,0),'constant',constant_values=(0))\n",
    "\n",
    "w = w[0:len(w)-r]\n",
    "\n",
    "s = dy\n",
    "\n",
    "n = np.lib.pad(dy,(1,0),'constant',constant_values=(0))\n",
    "\n",
    "n = n[0:(len(n) - 1)]\n",
    "\n",
    "D = 1-(e+w+s+n)\n",
    "\n",
    "A = reslapMat\n",
    "\n",
    "temp = np.transpose(D)\n",
    "\n",
    "A = A + np.transpose(A) + scipy.sparse.spdiags(temp, 0, k, k);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalize data weight\n",
    "\n",
    "data_term_weight = data_term_weight - min(data_term_weight.flatten())\n",
    "\n",
    "data_term_weight = np.divide(data_term_weight,max(data_term_weight.flatten()) + smallNum)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "reliability_mask = data_term_weight[0,:] < 0.6\n",
    "\n",
    "in_row1 = np.zeros((r_trans.shape[1]))\n",
    "\n",
    "for i in range(r_trans.shape[1]):\n",
    "        in_row1[i] = np.min(r_trans[:,i])\n",
    "\n",
    "data_term_weight[0,reliability_mask] = 0.8\n",
    "r_trans[0,reliability_mask] = in_row1[reliability_mask]\n",
    "\n",
    "Adata = scipy.sparse.spdiags(data_term_weight.flatten(), 0, k, k);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "Res1 = Adata + A\n",
    "Res2 = Adata*(r_trans.flatten())\n",
    "\n",
    "from scipy.sparse.linalg import spsolve\n",
    "\n",
    "x = spsolve(Res1,Res2)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((538900,), array([ 0.26586673,  0.32570625,  0.33027653, ...,  0.71264693,\n",
       "        -0.08683007,  0.641879  ]))"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape,x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "refined_trans = x.reshape((r,c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normBacklight.extend([(1-item) for item in normBacklight])\n",
    "\n",
    "newBacklight = np.array([normBacklight[0],normBacklight[1],normBacklight[2],1-normBacklight[0],1-normBacklight[1],1-normBacklight[2]])\n",
    "\n",
    "denoMax = max(newBacklight)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Estimating K\n",
    "\n",
    "K_list = []\n",
    "\n",
    "t_b,t_g,t_r = cv2.split(img)\n",
    "\n",
    "for i in range(img.shape[0]):\n",
    "    for j in range(img.shape[1]):\n",
    "        tempLS = []\n",
    "        tempLS.append(t_b[i][j]/256 - normBacklight[0])\n",
    "        tempLS.append(t_g[i][j]/256 - normBacklight[1])\n",
    "        tempLS.append(t_r[i][j]/256 - normBacklight[2])\n",
    "        K_list.append(max(tempLS)/denoMax)\n",
    "\n",
    "K = max(K_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abhishek/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:16: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  app.launch_new_instance()\n",
      "/home/abhishek/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/abhishek/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:18: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    }
   ],
   "source": [
    "normB = t_b/255\n",
    "normG = t_g/255\n",
    "normR = t_r/255\n",
    "normImg = img/255\n",
    "\n",
    "lambda_r = max(lamda_b,lamda_g)\n",
    "\n",
    "#Obaining the scene radiance\n",
    "\n",
    "J_b = np.zeros((img.shape[0],img.shape[1]))\n",
    "J_g = np.zeros((img.shape[0],img.shape[1]))\n",
    "J_r = np.zeros((img.shape[0],img.shape[1]))\n",
    "\n",
    "for i in range(img.shape[0]):\n",
    "    for j in range(img.shape[1]):\n",
    "        J_b[i,j] = (((normB[i,j] - normBacklight[0])/(max((K*(refined_trans[i,j]**lamda_b)),0.1))) + normBacklight[0])\n",
    "        J_g[i,j] = (((normG[i,j] - normBacklight[1])/(max((K*(refined_trans[i,j]**lamda_g)),0.1))) + normBacklight[1])\n",
    "        J_r[i,j] = (((normR[i,j] - normBacklight[2])/(max((K*(refined_trans[i,j]**lambda_r)),0.1))) + normBacklight[2])\n",
    "        \n",
    "        if np.isnan(J_b[i,j]) or J_b[i,j] < 0:\n",
    "            J_b[i,j] = normBacklight[0]\n",
    "        if np.isnan(J_g[i,j]) or J_g[i,j] < 0:\n",
    "            J_g[i,j] = normBacklight[1]\n",
    "        if np.isnan(J_r[i,j]) or J_r[i,j] < 0:\n",
    "            J_r[i,j] = normBacklight[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abhishek/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: RuntimeWarning: invalid value encountered in power\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.power(refined_trans[0,674],lambda_r) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "J_b = J_b*255\n",
    "J_g = J_g*255\n",
    "J_r = J_r*255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputImg = np.zeros((img.shape[0],img.shape[1],3),dtype=np.uint8)\n",
    "\n",
    "outputImg[:,:,0] = J_b\n",
    "outputImg[:,:,1] = J_g\n",
    "outputImg[:,:,2] = J_r\n",
    "\n",
    "cv2.imwrite('Try3Output6.png',outputImg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.isnan(refined_trans))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8583540482954545"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.58823529, 0.69019608, 0.3372549 ])"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normBacklight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5882352941176471"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normBacklight[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.where(normR==  0.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6924651162790698, 0.6924651162790698, 0.536416490486258)"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda_r,lamda_b,lamda_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.isnan(J_b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(J_b < 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
